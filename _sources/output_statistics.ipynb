{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output statistics\n",
    "\n",
    "After running your MIKE simulation, you would often want to make different kinds of summary statistics of your data - both for your own understanding and for communicating your results.\n",
    "\n",
    "Examples of statistics\n",
    "\n",
    "* Min, max, mean, standard deviation \n",
    "* Quantiles/percentiles (e.g. median, interquartile range, return period etc)\n",
    "* Probability/frequency of exceedance\n",
    "\n",
    "Types of aggregations\n",
    "\n",
    "* Total - aggregate all data to a single number \n",
    "* Temporal - aggregate all time steps; for a dfsu 2d, the result would be a map\n",
    "* Spatial - aggregate all elements to a single value per time step\n",
    "* Others: monthly, by layer, spatial bin, sub domain etc... \n",
    "\n",
    "Ways of calculating\n",
    "\n",
    "* [MIKEIO.Dataset](https://dhi.github.io/mikeio/dataset.html#methods) \n",
    "* [MIKEIO.generic](https://dhi.github.io/mikeio/generic.html) (temporal aggregations only; larger-than-memory)\n",
    "* custom code (typically with NumPy)\n",
    "\n",
    "\n",
    ":::{note}\n",
    "This section uses features introduced in MIKE IO v 0.10.1 (released 2021-10-26)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mikeio import Dfsu, generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For smaller dfs files (maybe up to 2GB) it can be convenient to read the data to memory before doing aggregations. The MIKEIO.Dataset class have several [methods](https://dhi.github.io/mikeio/dataset.html#methods) for aggregating data along an axis. See the generic section below for larger-than-memory data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = Dfsu(\"data/NorthSea_HD_and_windspeed.dfsu\")\n",
    "ds = dfs.read()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal aggregations: mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is to aggregate along the time axis - the output will therefore be a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm  = ds.mean()\n",
    "mean_ws = dsm[\"Wind speed\"]\n",
    "mean_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.plot(z=mean_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial aggregations \n",
    "\n",
    "The Dataset aggregation methods (e.g. mean) takes an `axis` argument. If we give it the spatial axis (or the string 'space'), it will produce a time series of spatially aggregated values. \n",
    "\n",
    "\n",
    ":::{note}\n",
    "It's important to note that the spatial aggregations here ignores element areas! Only average takes a weights argument. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.mean(axis=\"space\").to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Wind speed'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has other methods for calculating typical statistics, e.g. max, quantile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds[[\"Wind speed\"]].max(axis=\"space\").to_dataframe().plot(title=\"Max wind speed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[[\"Wind speed\"]].quantile(q=[0.1,0.5,0.9],axis=\"space\").to_dataframe().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to know that the element area is not taking into account when doing the spatial aggregations! Only Dataset.average supports weighted averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[[\"Wind speed\"]].mean(axis=\"space\").to_dataframe()\n",
    "df.columns = [\"Simple mean\"]\n",
    "area=dfs.get_element_area()\n",
    "df['Weighted'] = ds[[\"Wind speed\"]].average(axis=\"space\", weights=area).to_dataframe()\n",
    "df.plot(title=\"Mean wind speed (simple vs weighted by element area)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsq  = ds.quantile(q=[0.1,0.5,0.9])\n",
    "dsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to a new dfsu file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.write(\"NorthSea_Quantiles.dfsu\", dsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/mikezero_quantiles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total\n",
    "\n",
    "Aggregating over all data (both time and space) can be done from the Dataset in a few ways: \n",
    "\n",
    "* ds.describe() - will give you summary statistics like pandas df.describe()\n",
    "* using axis=None in ds.mean(), ds.min()\n",
    "* using standard NumPy aggregation functions on the Dataset data e.g. ds[\"Wind speed\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.min(axis=None).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"Wind speed\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic\n",
    "\n",
    "The [MIKEIO.generic](https://dhi.github.io/mikeio/generic.html) submodule can produce common **temporal** statistics on any dfs file (of any size). The output will be a new dfs file. Currently, generic has these methods for calculating statistics: \n",
    "\n",
    "* avg_time()\n",
    "* quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic.avg_time(\"data/NorthSea_HD_and_windspeed.dfsu\", \"NorthSea_avg.dfsu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = Dfsu(\"NorthSea_avg.dfsu\")\n",
    "ds = dfs.read(items=\"Wind speed\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.plot(ds[\"Wind speed\"], title=\"Mean wind speed\"); # this will fail for MIKE IO < 0.9.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic.quantile(\"data/NorthSea_HD_and_windspeed.dfsu\", \"NorthSea_Quantiles2.dfsu\", q=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/mikezero_quantiles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = Dfsu(\"data/NorthSea_HD_and_windspeed.dfsu\")\n",
    "ds = dfs.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset.aggregate\n",
    "\n",
    "With aggregate we can get Dataset statistics with our \"own\" function, e.g. standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dsa = ds.aggregate(func=np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.plot(dsa[\"Wind speed\"], label=\"Std [m/s]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceedance probability\n",
    "\n",
    "Let's find out how often the wind exceeds 12m/s in our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mikeio import Dataset, eum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = ds.n_timesteps\n",
    "one_to_zero = 1. - np.arange(1., nt + 1.)/nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ds[\"Wind speed\"][:,0]\n",
    "plt.plot(ds.time, val);\n",
    "plt.plot(ds.time[val>12], val[val>12],'.r');\n",
    "plt.axhline(y=12,color='r')\n",
    "plt.ylabel('Wind speed [m/s]')\n",
    "plt.title('How often is the wind speed above 12m/s (element 0)?');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(ds[\"Wind speed\"][:,0]), one_to_zero);\n",
    "plt.xlabel('Wind speed [m/s]')\n",
    "plt.ylabel('Probability of exceedance [-]')\n",
    "plt.axvline(x=12,color='r')\n",
    "plt.title('Wind speed exceedance in element 0');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty Dataset \n",
    "items=[eum.ItemInfo(eum.EUMType.Probability)]\n",
    "dse = Dataset(data=dfs.n_elements, time=\"2017-10-27\", items=items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 12\n",
    "for j in range(ds.n_elements):\n",
    "    # this is a naive and slow way of calculating this!\n",
    "    dat = ds[\"Wind speed\"][:,j]\n",
    "    dse[0][0,j] = np.interp(threshold, np.sort(dat), one_to_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.plot(dse*100, title=\"Wind speed exceeding 12 m/s\", \n",
    "    label=\"Time of Exceedance [%]\", cmap=\"YlOrRd\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hours = (ds.time[-1]-ds.time[0]).total_seconds()/3600\n",
    "dfs.plot(dse*total_hours, title=\"Wind speed exceeding 12 m/s\", \n",
    "    label=\"Exceedance [Hours]\", cmap=\"YlOrRd\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4041ee05ab07c15354d6207e763f17a216c3f5ccf08906343c2b4fd3fa7a6fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
