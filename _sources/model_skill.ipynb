{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "f4041ee05ab07c15354d6207e763f17a216c3f5ccf08906343c2b4fd3fa7a6fb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model skill assessment\n",
    "\n",
    "## Simple comparison\n",
    "\n",
    "Sometimes all your need is a simple comparison of two time series. The `fmskill.compare()` method does just that."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from mikeio import Dfs0\n",
    "import fmskill"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The model\n",
    "Can be either a dfs0 or a DataFrame. It needs to have a single item only. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_mod = 'data/SW/ts_storm_4.dfs0'\n",
    "df_mod = Dfs0(fn_mod).read(items=0).to_dataframe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The observation\n",
    "Can be either a dfs0, a DataFrame or a PointObservation object. It needs to have a single item only."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_obs = 'data/SW/eur_Hm0.dfs0'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### compare()\n",
    "The compare() method will return an object that can be used for scatter plots, skill assessment, time series plots etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c = fmskill.compare(fn_obs, df_mod)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.plot_timeseries();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Systematic vs random errors\n",
    "\n",
    "![](images/systematic_random_error.png)\n",
    "\n",
    "A model is an simplified version of a natural system, such as the ocean, and as such does not reflect every detail of the natural system.\n",
    "\n",
    "In order to validate if a model does capture the essential dynamics of the natural system, it can be helpful to classify the mismatch of the model and observations in two broad categories:\n",
    "* systematic errors\n",
    "* random errors\n",
    "\n",
    "A quantitativate assesment of a model involves calculating one or more model score, skill metrics, which in varying degrees capture systematic errors, random errors or a combination.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "**Bias** is an indication of systematic error. In the left figure above, the model has negative bias (modelled wave heights are lower thatn observed). Thus it is an indication that the model can be improved.\n",
    "\n",
    "**Root Mean Square Error** (rmse) is a combination of systematic and random error. It is a common metric to indicate the quality of a calibrated model, but less useful to understand the potential for further calibration since it captures both systematic and random errors.\n",
    "\n",
    "**Unbiased Root Mean Square Error** (urmse) is the unbiased version of Root Mean Square Error. Since the bias is removed, it only captures the random error.\n",
    "\n",
    "For a complete list of possible metrics, see the [Metrics section in the FMSkill docs](https://dhi.github.io/fmskill/api.html#metrics).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get a quantitative model skill, we use the .skill() method, which returns a table (similar to a DataFrame)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.skill()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default is a number of common metrics, but you are free to pick your favorite metrics."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.skill(metrics=[\"mae\",\"rho\",\"lin_slope\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A very common way to visualize model skill is to use a scatter plot.\n",
    "\n",
    "The scatter plot includes some additional features such as a 2d histogram, a Q-Q line and a regression line, but the appearance is highly configurable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.scatter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.scatter(binsize=0.5, \n",
    "          show_points=False,\n",
    "          xlim=[0,6], ylim=[0,6],\n",
    "          title=\"A calibrated model!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Taylor diagram\n",
    "\n",
    "A taylor diagram is a way to combine several statistics in a single plot, and is very useful to compare the skill of several models, or observations in a single plot."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c.taylor()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elaborate comparison"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from fmskill import PointObservation\n",
    "from fmskill import ModelResult, Connector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn = 'data/SW/HKZN_local_2017_DutchCoast.dfsu'\n",
    "mr = ModelResult(fn, name='HKZN_local', item=0)\n",
    "mr.dfs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "o1 = PointObservation('data/SW/HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\n",
    "o2 = PointObservation(\"data/SW/eur_Hm0.dfs0\", item=0, x=3.2760, y=51.9990, name=\"EPL\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "o1.hist();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "o1.plot(); "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connecting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "con = Connector([o1, o2], mr)\n",
    "con.observations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "con.plot_observation_positions();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc = con.extract()\n",
    "cc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc.skill().style(precision=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc[\"EPL\"].skill(metrics=\"mean_absolute_error\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc[\"HKNA\"].plot_timeseries(figsize=(10,5));"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc[\"EPL\"].scatter(figsize=(8,8), show_hist=True) #, ylim=[2,8], xlim=[1,10])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc[\"EPL\"].hist(bins=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cc[\"HKNA\"].scatter(binsize=0.25, cmap=\"viridis\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "con.plot_temporal_coverage();"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}